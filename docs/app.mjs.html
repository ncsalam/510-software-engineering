<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: app.mjs</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: app.mjs</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * the main application code.
 *
 * @module app
 */

import dotenv from "dotenv";
import { validateField, handleValidationErrors, validateChatExists } from "./server/validation.mjs";
import express from "express";
import * as db from "./server/chat-db.mjs";
import { getRestaurantData } from "./server/restaurant-data.mjs";

const { startOllama, send } = await import("./server/ollama-interface.mjs");

await getRestaurantData();

dotenv.config({ quiet: true });
const ollamaOk = await startOllama(process.env.OLLAMA_MODEL, process.env.OLLAMA_KEEP_ALIVE);
if (!ollamaOk) process.exit(1);
db.init();

export const PORT = process.env.PORT;
export const app = express();
app.use(express.static("src/public"));
app.use(express.json());

/*
making an API request:

POST /api/send HTTP/1.1
Content-Type: application/json

{ message : "your prompt goes here"}

response (accepted):
HTTP/1.1 200 OK
Content-Type: application/json

{response: "LLM response content here"}

minimal JS example:
fetch("/api/send", {
  method: "POST",
  headers: { "content-type": "application/json" },
  body: JSON.stringify({ message: "why is the sky blue?" }),
}).then(async (res) => console.log(await res.json()));
*/

/*
generate a one-off llm response.
required headers:
content-type: application/json

body format:
{
  message: "your message content"
}
*/
app.post(
  "/api/send", // endpoint path
  validateField("message"),
  handleValidationErrors,
  async (req, res) => {
    const llm_res = await send(
      process.env.OLLAMA_MODEL,
      [{ role: "user", content: req.body.message }],
      process.env.OLLAMA_KEEP_ALIVE
    );
    // return response from LLM
    res.json({
      response: llm_res.message.content,
    });
  }
);

/*
create a new chat with the LLM.

required headers:
none

response format (success):
{
  id: &lt;int>
}
*/
app.post("/api/chat", async (req, res) => {
  res.status(201).json({
    id: await db.newChat(),
  });
});

/*
generate a chat response from the llm. (aware of previous messages sent to this endpoint)

required headers:
content-type: application/json

body format:
{
  message: "your message content"
}

response format:
{
  response: "llm's response"
}
*/
app.post("/api/chat/:id", validateChatExists, validateField("message"), handleValidationErrors, async (req, res) => {
  // add user message to chat history
  await db.logMessage(req.params.id, "user", req.body.message);
  // build message array out of chat history and system prompts
  const chat = [
    {
      role: "system",
      content: process.env.OLLAMA_SYS_PROMPT,
    },
    {
      role: "system",
      content: process.env.OLLAMA_DATA_PROMPT + (await getRestaurantData()),
    },
    // TODO: inject another system prompt with relevant restaurant data for the LLM to use.
    ...(await db.getHistory(req.params.id)),
  ];
  // generate chat completion
  const llm_res = await send(process.env.OLLAMA_MODEL, chat, process.env.OLLAMA_KEEP_ALIVE);
  // log assistant response and return it
  await db.logMessage(req.params.id, "assistant", llm_res.message.content);
  res.json({
    response: llm_res.message.content,
  });
});

/*
delete an existing chat from the LLM history by id.
*/
app.delete("/api/chat/:id", validateChatExists, async (req, res) => {
  db.deleteChat(req.params.id);
  res.json({
    ok: true,
  });
});
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Modules</h3><ul><li><a href="module-app.html">app</a></li><li><a href="module-server_chat-db.html">server/chat-db</a></li><li><a href="module-server_ollama-interface.html">server/ollama-interface</a></li><li><a href="module-server_sqlite3-async.html">server/sqlite3-async</a></li><li><a href="module-server_terminal-helper.html">server/terminal-helper</a></li><li><a href="module-server_validation.html">server/validation</a></li><li><a href="module-src_public_llm_response.html">src/public/llm_response</a></li><li><a href="module-src_public_text-to-speech_preprocesss.html">src/public/text-to-speech/preprocesss</a></li><li><a href="module-src_public_text-to-speech_text-to-speech.html">src/public/text-to-speech/text-to-speech</a></li></ul><h3>Global</h3><ul><li><a href="global.html#wirePage">wirePage</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 4.0.5</a> on Wed Nov 05 2025 21:38:56 GMT-0500 (Eastern Standard Time)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
